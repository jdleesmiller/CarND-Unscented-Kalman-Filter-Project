{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import subprocess\n",
    "from os import path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from scipy.stats import chi2, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_path(set_number):\n",
    "    return 'data/sample-laser-radar-measurement-data-{}.txt'.format(set_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Run the UnscentedKF program with the given arguments and return the output.\n",
    "#\n",
    "def run(set_number, use_laser, use_radar, std_a, std_yawdd, lambd):\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        output_path = path.join(tmp, 'output.txt')\n",
    "        command = [\n",
    "          'build/UnscentedKF',\n",
    "          data_path(set_number),\n",
    "          output_path,\n",
    "          str(use_laser).lower(),\n",
    "          str(use_radar).lower(),\n",
    "          str(std_a),\n",
    "          str(std_yawdd),\n",
    "          str(lambd),\n",
    "          'true' # tweak output for reading by this tool\n",
    "        ]\n",
    "        result = subprocess.run(\n",
    "          command,\n",
    "          stdout=subprocess.PIPE,\n",
    "          stderr=subprocess.PIPE,\n",
    "          universal_newlines=True\n",
    "        )\n",
    "        with open(output_path, 'r') as output_file:\n",
    "            return result, output_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Since we've already computed the RMSEs, just extract them from stdout.\n",
    "#\n",
    "def extract_rmse(result):\n",
    "    if result.returncode != 0:\n",
    "        return None\n",
    "    lines = result.stdout.splitlines()\n",
    "    rmse_start = lines.index('Accuracy - RMSE:') + 1\n",
    "    rmse_end = rmse_start + 4\n",
    "    return [float(rmse) for rmse in lines[rmse_start:rmse_end]]\n",
    "\n",
    "SENSOR_INDEX = 11\n",
    "NIS_INDEX = 12\n",
    "\n",
    "def check_output_header_line(line):\n",
    "    fields = line.split()\n",
    "    assert len(fields) == 13\n",
    "    assert fields[SENSOR_INDEX] == 'sensor'\n",
    "    assert fields[NIS_INDEX] == 'NIS'\n",
    "\n",
    "def extract_nis(output):\n",
    "    check_output_header_line(output[0])\n",
    "    rows = [\n",
    "        output[i].split()\n",
    "        for i in range(1, len(output))\n",
    "    ]\n",
    "    return [\n",
    "        [float(row[NIS_INDEX]) for row in rows if row[SENSOR_INDEX] == sensor]\n",
    "        for sensor in ['L', 'R'] \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94499999999999995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# This is the NIS score test suggested in the lecture: find the expected NIS\n",
    "# based on the 95th percentile of the Chi^2 distribution with the relevant\n",
    "# number of degrees of freedom (e.g. NIS ~ 7.8 for 3 DoF). Then find the\n",
    "# percentage of observed NIS scores that are below that threshold. If the answer\n",
    "# is close to 95%, that suggests that the filter is consistent.\n",
    "#\n",
    "def find_nis_quantile(nis_scores, df, quantile=0.95):\n",
    "    if len(nis_scores) == 0: return float('nan')\n",
    "    threshold = chi2.ppf(quantile, df)\n",
    "    return sum(nis < threshold for nis in nis_scores) / len(nis_scores)\n",
    "\n",
    "# Check: this number should be about 0.95\n",
    "find_nis_quantile(chi2.rvs(2, size=1000), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010197440303248956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Compute the Kullbackâ€“Leibler divergence between the empirical distribution\n",
    "# of NIS scores and the Chi^2 distribution with the given number of degrees of\n",
    "# freedom. If the empirical distribution of the NIS scores is close to the\n",
    "# expected Chi^2 distribution, so the filter is consistent, then the returned\n",
    "# KL-div will be small.\n",
    "#\n",
    "def find_nis_kl_div(nis_scores, df, num_bins=21):\n",
    "    if len(nis_scores) == 0: return float('nan')\n",
    "    if not np.all(np.isfinite(nis_scores)): return float('nan')\n",
    "    # Pick the bins so that we expect an equal mass in each bin, according to\n",
    "    # the Chi^2 distribution with the appropriate number of degrees of freedom.\n",
    "    xs = np.linspace(0, 1, num_bins)\n",
    "    pk, _ = np.histogram(nis_scores, bins=chi2.ppf(xs, df))\n",
    "    pk = pk.astype(np.double) / np.sum(pk)\n",
    "    qk = np.diff(xs)\n",
    "    return entropy(pk, qk)\n",
    "\n",
    "# Check: this number should be near zero.\n",
    "find_nis_kl_div(chi2.rvs(2, size=1000), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://stackoverflow.com/a/40623158/2053820\n",
    "def dict_product(dicts):\n",
    "    \"\"\"\n",
    "    >>> list(dict_product(dict(number=[1,2], character='ab')))\n",
    "    [{'character': 'a', 'number': 1},\n",
    "     {'character': 'a', 'number': 2},\n",
    "     {'character': 'b', 'number': 1},\n",
    "     {'character': 'b', 'number': 2}]\n",
    "    \"\"\"\n",
    "    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(params):\n",
    "    result, output = run(**params)\n",
    "    if result.returncode == 0:\n",
    "        rmse = extract_rmse(result)\n",
    "        laser_nis_scores, radar_nis_scores = extract_nis(output)\n",
    "    else:\n",
    "        rmse = [float('inf')] * 4\n",
    "        laser_nis_scores = []\n",
    "        radar_nis_scores = []\n",
    "\n",
    "    laser_df = 2\n",
    "    radar_df = 3\n",
    "    return {\n",
    "        'px_rmse': rmse[0],\n",
    "        'py_rmse': rmse[1],\n",
    "        'vx_rmse': rmse[2],\n",
    "        'vy_rmse': rmse[3],\n",
    "        'laser_nis_kl_div': find_nis_kl_div(laser_nis_scores, laser_df),\n",
    "        'laser_nis_quantile': find_nis_quantile(laser_nis_scores, laser_df),\n",
    "        'radar_nis_kl_div': find_nis_kl_div(radar_nis_scores, radar_df),\n",
    "        'radar_nis_quantile': find_nis_quantile(radar_nis_scores, radar_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First grid:\n",
    "#         'std_a': np.linspace(0.1, 10, 20).tolist(),\n",
    "#         'std_yawdd': (math.pi / np.linspace(0.1, 10, 20)).tolist(),\n",
    "#         'lambd': np.linspace(-10, 10, 40).tolist()\n",
    "# Yielded only 30 out of 32000 points that met spec.\n",
    "# Narrowed the ranges for the second grid.\n",
    "# Then added a few more std_a and std_yawdd points, because the\n",
    "# best ones were near the edge of the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RESULTS_FILE = 'data/search.pickle'\n",
    "def search():\n",
    "    if path.isfile(RESULTS_FILE):\n",
    "        with open(RESULTS_FILE, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "\n",
    "    keys = {\n",
    "        'set_number': [1, 2],\n",
    "        'use_laser': [True],\n",
    "        'use_radar': [True],\n",
    "        'std_a': np.concatenate([\n",
    "            np.linspace(0.2, 0.5, 10),\n",
    "            np.linspace(0.3, 0.5, 10),\n",
    "            np.linspace(0.5, 2.0, 20)]).tolist(),\n",
    "        'std_yawdd': (math.pi / np.concatenate([\n",
    "                np.linspace(6.0, 8.0, 10),\n",
    "                np.linspace(4.0, 6.0, 20)])).tolist(),\n",
    "        'lambd': np.linspace(-6, -1, 20).tolist()\n",
    "    }\n",
    "\n",
    "    for key in dict_product(keys):\n",
    "        frozen_key = frozenset(key.items())\n",
    "        if frozen_key in results:\n",
    "            continue\n",
    "\n",
    "        results[frozen_key] = evaluate(key)\n",
    "\n",
    "        with open(RESULTS_FILE, 'wb') as f:\n",
    "            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21460"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_results():\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Pair up the dataset 1 and dataset 2 results --- we want to\n",
    "# consider both for each set of parameters.\n",
    "def group_results(results):\n",
    "    grouped_results = {}\n",
    "    for key, value in results.items():\n",
    "        key_dict = dict(key)\n",
    "        set_number = key_dict.pop('set_number')\n",
    "        key_without_set_number = frozenset(key_dict.items())\n",
    "        if key_without_set_number in grouped_results:\n",
    "            grouped_results[key_without_set_number][set_number] = value\n",
    "        else:\n",
    "            grouped_results[key_without_set_number] = {set_number: value}\n",
    "    return grouped_results\n",
    "\n",
    "GROUPED_RESULTS = group_results(load_results())\n",
    "len(GROUPED_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Apply max RMSE constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4842"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_single_rmse_vector(values):\n",
    "    return np.array([\n",
    "        values['px_rmse'],\n",
    "        values['py_rmse'],\n",
    "        values['vx_rmse'],\n",
    "        values['vy_rmse'],\n",
    "    ])\n",
    "\n",
    "def make_rmse_vector(values):\n",
    "    return np.concatenate([\n",
    "        make_single_rmse_vector(values[1]),\n",
    "        make_single_rmse_vector(values[2])\n",
    "    ])\n",
    "\n",
    "MAX_RMSES = {\n",
    "    1: {\n",
    "        'px_rmse': 0.09,\n",
    "        'py_rmse': 0.09,\n",
    "        'vx_rmse': 0.65,\n",
    "        'vy_rmse': 0.65\n",
    "    },\n",
    "    2: {\n",
    "        'px_rmse': 0.20,\n",
    "        'py_rmse': 0.20,\n",
    "        'vx_rmse': 0.55,\n",
    "        'vy_rmse': 0.55\n",
    "    }\n",
    "}\n",
    "MAX_RMSE_VECTOR = make_rmse_vector(MAX_RMSES)\n",
    "\n",
    "def is_result_in_spec(value):\n",
    "    rmse_vector = make_rmse_vector(value)\n",
    "    if np.any(np.isnan(rmse_vector)):\n",
    "        return False\n",
    "    return np.all(rmse_vector <= MAX_RMSE_VECTOR)\n",
    "\n",
    "# We need it to be in spec for both dataset 1 and dataset 2.  \n",
    "def find_results_in_spec(results):\n",
    "    return {\n",
    "        key: value\n",
    "        for key, value in results.items()\n",
    "        if is_result_in_spec(value)\n",
    "    }\n",
    "\n",
    "def make_single_nis_vector(values, consistency_score):\n",
    "    return np.array([\n",
    "        values['laser_nis_' + consistency_score],\n",
    "        values['radar_nis_' + consistency_score]\n",
    "    ])\n",
    "\n",
    "def make_nis_vector(values, consistency_score):\n",
    "    return np.concatenate([\n",
    "        make_single_nis_vector(values[1], consistency_score),\n",
    "        make_single_nis_vector(values[2], consistency_score)\n",
    "    ])\n",
    "\n",
    "def make_result_vector(values, consistency_score):\n",
    "    return np.concatenate([\n",
    "        make_single_rmse_vector(values[1]),\n",
    "        make_single_nis_vector(values[1], consistency_score),\n",
    "        make_single_rmse_vector(values[2]),\n",
    "        make_single_nis_vector(values[2], consistency_score)\n",
    "    ])\n",
    "\n",
    "# v1 dominates v2 if all entries of v1 are smaller\n",
    "def dominates(v1, v2):\n",
    "    return np.all(v1 < v2)\n",
    "\n",
    "def find_non_dominated(results, consistency_score):\n",
    "    keys = list(results.keys())\n",
    "    vectors = [\n",
    "        make_result_vector(results[keys[i]], consistency_score)\n",
    "        for i in range(len(keys))\n",
    "    ]\n",
    "    return {\n",
    "        keys[i]: results[keys[i]]\n",
    "        for i in range(len(keys))\n",
    "        if not any(\n",
    "            dominates(vectors[j], vectors[i])\n",
    "            for j in range(len(keys)))\n",
    "    }\n",
    "\n",
    "RESULTS_IN_SPEC = find_results_in_spec(GROUPED_RESULTS)\n",
    "len(RESULTS_IN_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4834"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NON_DOMINATED_KL_DIV_RESULTS = \\\n",
    "    find_non_dominated(RESULTS_IN_SPEC, 'kl_div')\n",
    "len(NON_DOMINATED_KL_DIV_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset({('lambd', -1.526315789473684),\n",
       "            ('std_a', 0.3666666666666667),\n",
       "            ('std_yawdd', 0.552687596464871),\n",
       "            ('use_laser', True),\n",
       "            ('use_radar', True)}),\n",
       " array([ 0.0768951 ,  0.0842682 ,  0.596263  ,  0.57953   ,  0.43099722,\n",
       "         0.25169172,  0.195603  ,  0.18771   ,  0.290216  ,  0.523151  ,\n",
       "         0.3310879 ,  0.81138413]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom = list(set(RESULTS_IN_SPEC) - set(NON_DOMINATED_KL_DIV_RESULTS))[0]\n",
    "domv = make_result_vector(RESULTS_IN_SPEC[dom], 'kl_div')\n",
    "(dom, domv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({('lambd', -2.0526315789473686),\n",
       "             ('std_a', 0.3888888888888889),\n",
       "             ('std_yawdd', 0.552687596464871),\n",
       "             ('use_laser', True),\n",
       "             ('use_radar', True)}),\n",
       "  array([ 0.0767982 ,  0.0839924 ,  0.596012  ,  0.579288  ,  0.4298233 ,\n",
       "          0.24790862,  0.194879  ,  0.187557  ,  0.28153   ,  0.50407   ,\n",
       "          0.32986809,  0.76055473]))]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    (key, make_result_vector(value, 'kl_div'))\n",
    "    for key, value in RESULTS_IN_SPEC.items()\n",
    "    if dominates(make_result_vector(value, 'kl_div'), domv)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def average_rmse(rmses):\n",
    "    return np.sqrt(np.dot(rmses, rmses) / len(rmses))\n",
    "    \n",
    "def plot_in_parameter_space(results, size_scale=30):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    data = np.array([\n",
    "        [\n",
    "            dict(key)['std_a'],\n",
    "            dict(key)['std_yawdd'],\n",
    "            dict(key)['lambd'],\n",
    "            size_scale * np.mean(make_nis_vector(value, 'kl_div')),\n",
    "            average_rmse(make_rmse_vector(value))\n",
    "        ]\n",
    "        for key, value in results.items()\n",
    "    ])\n",
    "    p = ax.scatter(data[:,0], data[:,1], data[:,2],\n",
    "                   s=data[:,3], c=data[:,4], cmap='cool')\n",
    "    ax.set_xlabel('std_a')\n",
    "    ax.set_ylabel('std_yawdd')\n",
    "    ax.set_zlabel('lambda')\n",
    "    fig.colorbar(p)\n",
    "    \n",
    "plot_in_parameter_space(NON_DOMINATED_KL_DIV_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333333333333337 0.5235987755982988 -5.473684210526316 0.312495913273 0.36603127876\n",
      "0.26666666666666666 0.5329487537339828 -4.684210526315789 0.380464991037 0.360401629196\n",
      "0.26666666666666666 0.5426387310746007 -5.473684210526316 0.320188873935 0.363810472886\n",
      "0.26666666666666666 0.5329487537339828 -5.473684210526316 0.32571985334 0.363269151905\n",
      "0.30000000000000004 0.5235987755982988 -4.947368421052632 0.353903201299 0.361273356852\n",
      "0.3 0.5235987755982988 -4.947368421052632 0.353903201299 0.361273356852\n",
      "0.23333333333333334 0.552687596464871 -5.473684210526316 0.32841632889 0.363204877381\n",
      "0.3 0.5235987755982988 -5.2105263157894735 0.340133074897 0.362233943089\n",
      "0.26666666666666666 0.5329487537339828 -5.2105263157894735 0.341408405975 0.361421288147\n",
      "0.4666666666666667 0.5235987755982988 -5.2105263157894735 0.305383801662 0.370134445195\n",
      "0.30000000000000004 0.5235987755982988 -5.2105263157894735 0.340133074897 0.362233943089\n",
      "0.26666666666666666 0.5329487537339828 -4.947368421052632 0.357796607849 0.360608440205\n"
     ]
    }
   ],
   "source": [
    "def plot_in_objective_space(results, consistency_score, pareto_only):\n",
    "    keys = list(results.keys())\n",
    "    values = [results[key] for key in keys]\n",
    "    data = np.array([\n",
    "        [\n",
    "            np.mean(make_nis_vector(value, consistency_score)),\n",
    "            average_rmse(make_rmse_vector(value))\n",
    "        ]\n",
    "        for value in values\n",
    "    ])\n",
    "    \n",
    "    if pareto_only:\n",
    "        indexes = [\n",
    "            i\n",
    "            for i in range(len(keys))\n",
    "            if not any (\n",
    "                np.all(data[j,:] < data[i,:])\n",
    "                for j in range(len(keys))\n",
    "            )\n",
    "        ]\n",
    "        for i in indexes:\n",
    "            key_i = dict(keys[i])\n",
    "            print(key_i['std_a'], key_i['std_yawdd'], key_i['lambd'],\n",
    "                  data[i,0], data[i,1])\n",
    "    else:\n",
    "        indexes = range(len(keys))        \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(data[indexes,0], data[indexes,1])\n",
    "    \n",
    "    for i in indexes:\n",
    "        key = dict(keys[i])\n",
    "        text = \"{std_a:.3f},{std_yawdd:.3f},{lambd:.3f}\".format(**key)\n",
    "        ax.annotate(text, (data[i,0], data[i,1]))\n",
    "    \n",
    "    plt.xlabel('average NIS ' + consistency_score)\n",
    "    plt.ylabel('average RMSE')\n",
    "plot_in_objective_space(NON_DOMINATED_KL_DIV_RESULTS, 'kl_div', pareto_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.5851986315510399 -5.2105263157894735 0.938382352941 0.362935120189\n",
      "0.23333333333333334 0.5739448117135199 -5.2105263157894735 0.940065359477 0.362132642887\n",
      "0.26666666666666666 0.5739448117135199 -5.473684210526316 0.933382352941 0.366149586484\n",
      "0.23333333333333334 0.552687596464871 -5.473684210526316 0.935065359477 0.363204877381\n",
      "0.23333333333333334 0.552687596464871 -5.2105263157894735 0.942565359477 0.361386002991\n",
      "0.26666666666666666 0.5329487537339828 -4.947368421052632 0.944656862745 0.360608440205\n",
      "0.30000000000000004 0.5426387310746007 -5.473684210526316 0.934248366013 0.365533502719\n",
      "0.26666666666666666 0.5329487537339828 -5.473684210526316 0.934656862745 0.363269151905\n",
      "0.23333333333333334 0.552687596464871 -4.684210526315789 0.945065359477 0.360582828011\n",
      "0.3 0.5426387310746007 -5.473684210526316 0.934248366013 0.365533502719\n",
      "0.3 0.5329487537339828 -5.473684210526316 0.934248366013 0.364848910003\n",
      "0.30000000000000004 0.5329487537339828 -5.473684210526316 0.934248366013 0.364848910003\n",
      "0.23333333333333334 0.6350027704064475 -5.473684210526316 0.931699346405 0.370380314039\n",
      "0.30000000000000004 0.552687596464871 -5.473684210526316 0.932565359477 0.366368512749\n",
      "0.23333333333333334 0.5631156643226988 -5.2105263157894735 0.942565359477 0.361722605251\n",
      "0.3 0.552687596464871 -5.473684210526316 0.932565359477 0.366368512749\n",
      "0.26666666666666666 0.5329487537339828 -4.684210526315789 0.947156862745 0.360401629196\n"
     ]
    }
   ],
   "source": [
    "plot_in_objective_space(RESULTS_IN_SPEC, 'quantile', pareto_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({1: {'laser_nis_kl_div': 0.36708907635530003,\n",
       "    'laser_nis_quantile': 1.0,\n",
       "    'px_rmse': 0.0790429,\n",
       "    'py_rmse': 0.0895979,\n",
       "    'radar_nis_kl_div': 0.24062287776881455,\n",
       "    'radar_nis_quantile': 0.81862745098039214,\n",
       "    'vx_rmse': 0.60153,\n",
       "    'vy_rmse': 0.585284},\n",
       "   2: {'laser_nis_kl_div': 0.18545954058779751,\n",
       "    'laser_nis_quantile': 0.96999999999999997,\n",
       "    'px_rmse': 0.181726,\n",
       "    'py_rmse': 0.187455,\n",
       "    'radar_nis_kl_div': 0.57246212918647921,\n",
       "    'radar_nis_quantile': 0.98999999999999999,\n",
       "    'vx_rmse': 0.292168,\n",
       "    'vy_rmse': 0.415699}},\n",
       "  {'lambd': -5.2105263157894735,\n",
       "   'std_a': 0.26666666666666666,\n",
       "   'std_yawdd': 0.5329487537339828,\n",
       "   'use_laser': True,\n",
       "   'use_radar': True}),\n",
       " ({1: {'laser_nis_kl_div': 0.37602558621686799,\n",
       "    'laser_nis_quantile': 1.0,\n",
       "    'px_rmse': 0.0778441,\n",
       "    'py_rmse': 0.0892303,\n",
       "    'radar_nis_kl_div': 0.23562352598140654,\n",
       "    'radar_nis_quantile': 0.8202614379084967,\n",
       "    'vx_rmse': 0.599763,\n",
       "    'vy_rmse': 0.584357},\n",
       "   2: {'laser_nis_kl_div': 0.15062970641096646,\n",
       "    'laser_nis_quantile': 0.93000000000000005,\n",
       "    'px_rmse': 0.179589,\n",
       "    'py_rmse': 0.187594,\n",
       "    'radar_nis_kl_div': 0.51847667712931222,\n",
       "    'radar_nis_quantile': 0.98999999999999999,\n",
       "    'vx_rmse': 0.307522,\n",
       "    'vy_rmse': 0.426193}},\n",
       "  {'lambd': -5.473684210526316,\n",
       "   'std_a': 0.26666666666666666,\n",
       "   'std_yawdd': 0.5426387310746007,\n",
       "   'use_laser': True,\n",
       "   'use_radar': True}),\n",
       " ({1: {'laser_nis_kl_div': 0.36543107306395406,\n",
       "    'laser_nis_quantile': 1.0,\n",
       "    'px_rmse': 0.0789759,\n",
       "    'py_rmse': 0.0899533,\n",
       "    'radar_nis_kl_div': 0.24051568304611065,\n",
       "    'radar_nis_quantile': 0.81862745098039214,\n",
       "    'vx_rmse': 0.6017,\n",
       "    'vy_rmse': 0.58568},\n",
       "   2: {'laser_nis_kl_div': 0.17450639733492079,\n",
       "    'laser_nis_quantile': 0.93000000000000005,\n",
       "    'px_rmse': 0.179267,\n",
       "    'py_rmse': 0.187533,\n",
       "    'radar_nis_kl_div': 0.52242625991359304,\n",
       "    'radar_nis_quantile': 0.98999999999999999,\n",
       "    'vx_rmse': 0.303938,\n",
       "    'vy_rmse': 0.420285}},\n",
       "  {'lambd': -5.473684210526316,\n",
       "   'std_a': 0.26666666666666666,\n",
       "   'std_yawdd': 0.5329487537339828,\n",
       "   'use_laser': True,\n",
       "   'use_radar': True}),\n",
       " ({1: {'laser_nis_kl_div': 0.37868048606171933,\n",
       "    'laser_nis_quantile': 1.0,\n",
       "    'px_rmse': 0.0772077,\n",
       "    'py_rmse': 0.0897146,\n",
       "    'radar_nis_kl_div': 0.24233808724237924,\n",
       "    'radar_nis_quantile': 0.8202614379084967,\n",
       "    'vx_rmse': 0.59837,\n",
       "    'vy_rmse': 0.583565},\n",
       "   2: {'laser_nis_kl_div': 0.14650841486039806,\n",
       "    'laser_nis_quantile': 0.93000000000000005,\n",
       "    'px_rmse': 0.181329,\n",
       "    'py_rmse': 0.187722,\n",
       "    'radar_nis_kl_div': 0.54613832739388346,\n",
       "    'radar_nis_quantile': 0.98999999999999999,\n",
       "    'vx_rmse': 0.302744,\n",
       "    'vy_rmse': 0.427743}},\n",
       "  {'lambd': -5.473684210526316,\n",
       "   'std_a': 0.23333333333333334,\n",
       "   'std_yawdd': 0.552687596464871,\n",
       "   'use_laser': True,\n",
       "   'use_radar': True}),\n",
       " ({1: {'laser_nis_kl_div': 0.36459345807181237,\n",
       "    'laser_nis_quantile': 1.0,\n",
       "    'px_rmse': 0.079922,\n",
       "    'py_rmse': 0.0895622,\n",
       "    'radar_nis_kl_div': 0.2328553686796522,\n",
       "    'radar_nis_quantile': 0.81699346405228757,\n",
       "    'vx_rmse': 0.603107,\n",
       "    'vy_rmse': 0.586335},\n",
       "   2: {'laser_nis_kl_div': 0.19507111357750478,\n",
       "    'laser_nis_quantile': 0.96999999999999997,\n",
       "    'px_rmse': 0.180566,\n",
       "    'py_rmse': 0.187467,\n",
       "    'radar_nis_kl_div': 0.56801235925725457,\n",
       "    'radar_nis_quantile': 0.98999999999999999,\n",
       "    'vx_rmse': 0.296787,\n",
       "    'vy_rmse': 0.414658}},\n",
       "  {'lambd': -5.2105263157894735,\n",
       "   'std_a': 0.3,\n",
       "   'std_yawdd': 0.5235987755982988,\n",
       "   'use_laser': True,\n",
       "   'use_radar': True})]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_weighted_score(value, rmse_weight,\n",
    "                        consistency_weight, consistency_score):\n",
    "    consistency = np.mean(make_nis_vector(value, consistency_score))\n",
    "    # Want to be as close to 0.95 as possible.\n",
    "    if consistency_score == 'quantile':\n",
    "        consistency = np.abs(consistency - 0.95)\n",
    "    return \\\n",
    "        rmse_weight * average_rmse(make_rmse_vector(value)) + \\\n",
    "        consistency_weight * consistency\n",
    "    \n",
    "def find_top_results(\n",
    "    results, n,\n",
    "    rmse_weight=1,\n",
    "    consistency_weight=0.1,\n",
    "    consistency_score='kl_div'):\n",
    "    sorted_results = sorted(\n",
    "        results.items(),\n",
    "        key=lambda pair: find_weighted_score(\n",
    "            pair[1], rmse_weight, consistency_weight, consistency_score))\n",
    "    return [\n",
    "        (value, dict(key))\n",
    "        for key, value in sorted_results\n",
    "    ][0:n]\n",
    "find_top_results(NON_DOMINATED_KL_DIV_RESULTS, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# could do a grid, or we could use an optimiser...\n",
    "# but I guess it's multiobjective\n",
    "# and it's pretty quick.\n",
    "# probably simpler to just grid it out\n",
    "\n",
    "# record for each param setting:\n",
    "#   for each dataset:\n",
    "#     RMSEs\n",
    "#     NIS quantile\n",
    "#     NIS KLDIV\n",
    "#     or a failure code\n",
    "# then I guess we want another script to thin it out with:\n",
    "#  - not a numerical failure\n",
    "#  - meets spec in terms of RMSEs on DS1 and DS2\n",
    "#  - not dominated in terms of the 8 RMSEs and 2 KLdivs (pareto)\n",
    "#\n",
    "# can't plot 10 dimensions, but can project into mean RMSE and mean KLdiv space\n",
    "# and we only have 3 real params, so we can do a 3d plot\n",
    "\n",
    "# odd that we didn't get any dominated solutions... maybe a bug\n",
    "# but maybe we should instead do pareto on the 2d plot. That looks like we could do\n",
    "# some pareto analysis to get a small number of solutions."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
